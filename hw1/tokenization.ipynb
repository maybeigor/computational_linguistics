{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6986f8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.2.1-cp38-cp38-macosx_10_9_x86_64.whl (9.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.0 MB 3.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.3.2 in ./.pyenv/versions/3.8.12/lib/python3.8/site-packages (from scikit-learn) (1.9.3)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: joblib>=1.1.1 in ./.pyenv/versions/3.8.12/lib/python3.8/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in ./.pyenv/versions/3.8.12/lib/python3.8/site-packages (from scikit-learn) (1.23.5)\n",
      "Installing collected packages: threadpoolctl, scikit-learn\n",
      "Successfully installed scikit-learn-1.2.1 threadpoolctl-3.1.0\n",
      "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 23.0 is available.\n",
      "You should consider upgrading via the '/Users/anastasiaalimova/.pyenv/versions/3.8.12/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# ! pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "2dffe57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ночь', 'улица', 'фонарь', 'аптека', 'Бессмысленный', 'и', 'тусклый', 'свет', 'Живи', 'еще', 'хоть', 'четверть', 'века', 'Всё', 'будет', 'так', 'Исхода', 'нет']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"Ночь, улица, фонарь, аптека, Бессмысленный и тусклый свет. Живи еще хоть четверть века — Всё будет так. Исхода нет.'\"\n",
    "tokens = re.findall(r'\\b\\w+(?:-\\w+)*\\b', text, flags=re.IGNORECASE)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "8dae26e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    \"\"\"\n",
    "    разбиение на токены (слова)\n",
    "    предложения разбиваются на слова, причем сокращенич типа (т.к.) будут считаться одним словом\n",
    "    \"\"\"\n",
    "    token_pattern = r'\\b(?:[А-Яа-яЁё]\\.)+[А-Яа-яЁё]?\\.?|\\b\\w+(?:-\\w+)*\\b'\n",
    "    tokens = re.findall(token_pattern, text, flags=re.IGNORECASE)\n",
    "    return tokens\n",
    "\n",
    "def split_sentences(text):\n",
    "    \"\"\"\n",
    "    Регулярное выражение для разбиения текста на предложения.\n",
    "    Согласно правилам русской грамматики, предложение начинается с заглавной буквы\n",
    "    и заканчивается точкой, восклицательным или вопросительным знаком.\n",
    "    \"\"\"\n",
    "    pattern = r'(?<!\\w\\.\\w.)(?<![А-ЯЁ][а-яё]\\.)(?<=\\.|\\?|\\!)\\s'\n",
    "    \n",
    "    # Разбиваем текст на предложения, используя регулярное выражение\n",
    "    sentences = re.split(pattern, text)\n",
    "    # Удаляем знаки препинания в конце предложений\n",
    "    sentences = [sentence.strip('.').strip('?').strip('!') for sentence in sentences if sentence.strip()]\n",
    "    \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "8fa7339e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат токенизации по словам:\n",
      " ['Ночь', 'улица', 'фонарь', 'аптека', 'Бессмысленный', 'и', 'тусклый', 'свет', 'Живи', 'еще', 'хоть', 'четверть', 'века', 'Всё', 'будет', 'так', 'Исхода', 'нет'] \n",
      "\n",
      "Разбиение на предложения:\n",
      " ['Ночь, улица, фонарь, аптека, Бессмысленный и тусклый свет', 'Живи еще хоть четверть века — Всё будет так', 'Исхода нет'] \n",
      "\n",
      "Результат токенизации по словам текста 2:\n",
      " ['Я', 'люблю', 'мороженое', 'т.к.', 'оно', 'вкусное']\n"
     ]
    }
   ],
   "source": [
    "# Пример использования\n",
    "text = 'Ночь, улица, фонарь, аптека, Бессмысленный и тусклый свет. Живи еще хоть четверть века — Всё будет так. Исхода нет.'\n",
    "text_2 = 'Я люблю мороженое, т.к. оно вкусное!'\n",
    "\n",
    "print(\"Результат токенизации по словам:\\n\", tokenize_text(text), '\\n')\n",
    "print(\"Разбиение на предложения:\\n\", split_sentences(text), '\\n')\n",
    "\n",
    "print(\"Результат токенизации по словам текста 2:\\n\", tokenize_text(text_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89986b1",
   "metadata": {},
   "source": [
    "Чтобы изменить функцию nltk_tokenization так, чтобы в результате получался список списков токенов предложений, мы можем использовать sent_tokenize из библиотеки NLTK для разделения текста на предложения, а затем применить word_tokenize к каждому предложению, чтобы получить список токенов для каждого предложения. Вот как будет выглядеть новый код:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "a5e154db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Ночь', ',', 'улица', ',', 'фонарь', ',', 'аптека', ',', 'Бессмысленный', 'и', 'тусклый', 'свет', '.'], ['Живи', 'еще', 'хоть', 'четверть', 'века', '—', 'Всё', 'будет', 'так.', 'Исхода', 'нет', '.']] \n",
      "\n",
      "[['Я', 'люблю', 'мороженое', ',', 'т.к.', 'оно', 'вкусное', '!'], ['И', 'полезное']]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def nltk_tokenization(text):\n",
    "    # применяем готовую функцию из nltk \n",
    "    # разбиваем текст на предложения\n",
    "    sentences = nltk.sent_tokenize(text, language='russian')\n",
    "    \n",
    "    # токенизируем каждое предложение и сохраняем результат в списке\n",
    "    tokenized_sentences = []\n",
    "    for sentence in sentences:\n",
    "        tokenized_sentence = nltk.word_tokenize(sentence, language='russian')\n",
    "        tokenized_sentences.append(tokenized_sentence)\n",
    "    \n",
    "    return tokenized_sentences\n",
    "\n",
    "\n",
    "text = 'Ночь, улица, фонарь, аптека, Бессмысленный и тусклый свет. Живи еще хоть четверть века — Всё будет так. Исхода нет.'\n",
    "text_2 = 'Я люблю мороженое, т.к. оно вкусное! И полезное'\n",
    "\n",
    "text_tokens = nltk_tokenization(text)\n",
    "text_2_tokens = nltk_tokenization(text_2)\n",
    "\n",
    "print(text_tokens, '\\n')\n",
    "print(text_2_tokens)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "3775c531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Последние',\n",
       "  'новости',\n",
       "  'SpaceX',\n",
       "  'запускает',\n",
       "  'новую',\n",
       "  'миссию',\n",
       "  'в',\n",
       "  'космос'],\n",
       " ['В',\n",
       "  'рамках',\n",
       "  'миссии',\n",
       "  'запланировано',\n",
       "  'выведение',\n",
       "  'на',\n",
       "  'орбиту',\n",
       "  'нескольких',\n",
       "  'спутников',\n",
       "  'и',\n",
       "  'отправка',\n",
       "  'груза',\n",
       "  'на',\n",
       "  'Международную',\n",
       "  'космическую',\n",
       "  'станцию'],\n",
       " ['Запуск', 'состоится', 'завтра', 'в', '10:00', 'утра']]"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = 'Последние новости: SpaceX запускает новую миссию в космос! В рамках миссии запланировано выведение на орбиту нескольких спутников и отправка груза на Международную космическую станцию. Запуск состоится завтра в 10:00 утра.'\n",
    "del_punct(nltk_tokenization(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "d039d6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_punct(token_list):\n",
    "    \"\"\" \n",
    "    удаляем знаки отдельно стоящие знаки препинания из списка списков токенов\n",
    "    \"\"\"\n",
    "    new_token_list = []\n",
    "    for sentence_tokens in token_list:\n",
    "        tokens = [elem for elem in sentence_tokens if elem not in [',', '.', '—', '–', '!', '?', ':', ';', '\"', '«', '»']]\n",
    "        new_token_list.append(tokens)\n",
    "    return new_token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "215deebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Я', 'люблю', 'мороженое', 'т.к.', 'оно', 'вкусное'], ['И', 'полезное']]"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_2_tokens = del_punct(text_2_tokens)\n",
    "text_2_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16be570",
   "metadata": {},
   "source": [
    "Тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "828f307c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_path):\n",
    "    \"\"\"\n",
    "    читает текстовый файл и возвращает строку с текстом содержимого\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    return text.replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "9c114d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Аннотация Предмет. Проблема бедности играет доминирующую роль в экономике России не только как «социальная болезнь», но и как образец поведения населения и фактор, влияющий на множество важных показателей страны. Бедность – это многомерное явление, являющееся результатом влияния большого количества факторов, которые, с одной стороны, воздействуют на все сферы общественного воспроизводства, а с другой – могут быть порождены социально-психологической сущностью самого человека. В данной статье понятие «бедность» рассматривается с точки зрения институционального подхода. Цели. Комплексное авторское исследование проблемы институционализации бедности в России. Выработка качественно новой стратегии социально-экономического развития, которая будет ориентирована прежде всего на предупреждение бедности и на борьбу с ее причинами в Российской Федерации. Методология. В процессе исследования проблемы институционализации бедности использовались методы логического, статистического анализа. Результаты. На территории Волгоградской области неудовлетворительно ведется борьба с бедностью населения, недостаточно используются возможности региона по улучшению уровня жизни населения. Основными направлениями формирования институционального механизма борьбы с бедностью в России и, в частности, в Волгоградской области является работа общественных объединений, фондов, организация банками микрофинансирования предпринимательства, предоставление образовательных кредитов для получения молодежью качественного образования, трудоустройство молодежи и предоставление ей возможности переквалификации в рамках социальной ответственности работодателей. \n",
      "\n",
      "— Ах, не говорите мне про Австрию! Я ничего не понимаю, может быть, но Австрия никогда не хотела и не хочет войны. Она предает нас. Россия одна должна быть спасительницей Европы. Наш благодетель знает свое высокое призвание и будет верен ему. Вот одно, во что я верю. Нашему доброму и чудному государю предстоит величайшая роль в мире, и он так добродетелен и хорош, что Бог не оставит его, и он исполнит свое призвание задавить гидру революции, которая теперь еще ужаснее в лице этого убийцы и злодея. Мы одни должны искупить кровь праведника. На кого нам надеяться, я вас спрашиваю?.. Англия с своим коммерческим духом не поймет и не может понять всю высоту души императора Александра. Она отказалась очистить Мальту. Она хочет видеть, ищет заднюю мысль наших действий. Что они сказали Новосильцеву? Ничего. Они не поняли, они не могли понять самоотвержения нашего императора, который ничего не хочет для себя и все хочет для блага мира. И что они обещали? Ничего. И что обещали, и того не будет! Пруссия уже объявила, что Бонапарте непобедим и что вся Европа ничего не может против него... И я не верю ни в одном слове ни Гарденбергу, ни Гаугвицу. Я верю в одного Бога и в высокую судьбу нашего милого императора. Он спасет Европу!.. — Она вдруг остановилась с улыбкой насмешки над своею горячностью. — Я думаю, — сказал князь, улыбаясь, — что, ежели бы вас послали вместо нашего милого Винценгероде, вы бы взяли приступом согласие прусского короля. Вы так красноречивы. Вы дадите мне чаю? \n",
      "\n",
      "В самый разгар пандемии актриса и телеведущая Джоанна Ламли отправляется в эпическое и очень личное путешествие по родной Великобритании. Она объедет самые разные уголки Англии, Шотландии, Уэльса и Северной Ирландии, познакомит нас с природными красотами и удивительными достопримечательностями этой многогранной страны. Мы побываем в местах, где снимали \"Игру престолов\", где Брэм Стокер писал своего \"Дракулу\", а Беатрис Поттер - истории про Кролика Питера. От Гебридских островов до графства Корнуолл, от \"английской Ривьеры\" до Шотландского нагорья, отправляйтесь с нами в путешествие по этому крошечному, но удивительно разнообразному острову. 16 февраля 1923 года английский археолог Говард Картер стал первым человеком за 3000 лет, вошедшим в погребальную камеру фараона Тутанхамона в Долине Царей. За свою недолгую жизнь (а скончался он, не дожив до 19-ти) Тутанхамон не совершил ничего примечательного, однако по иронии судьбы именно ему было суждено стать самым известным правителем Древнего Египта - как раз благодаря своей гробнице. При этом сам Картер, совершивший одно из величайших археологических открытий в истории человечества, формального образования практически не имел и фактически был самоучкой.\n"
     ]
    }
   ],
   "source": [
    "# Исходные тексты\n",
    "text_1 = read_file(\"Текст научной статьи.txt\")\n",
    "print(text_1, '\\n')\n",
    "text_2 = read_file(\"текст художественный.txt\")\n",
    "print(text_2, '\\n')\n",
    "text_3 = read_file(\"текст новостной статьи.txt\")\n",
    "print(text_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "e1ba865c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_txt_get_sentenses(file_name):\n",
    "    \"\"\"\n",
    "    Читайем в файл с текстами, вручную разбитыми на токены и разделенными на предложения и возвращаем список из всех предложений\n",
    "    \"\"\"\n",
    "\n",
    "    with open(file_name) as file:\n",
    "        text = file.read()\n",
    "\n",
    "    sentenses = [sentense.strip() for sentense in text.strip(\"\\n| \").split(\"|\")]\n",
    "    \n",
    "    return sentenses\n",
    "\n",
    "\n",
    "def read_txt_get_tokens(file_name):\n",
    "    \"\"\"\n",
    "    Читайем в файл с текстами, вручную разбитыми на токены и разделенными на предложения и возвращаем список токенов\n",
    "    \"\"\"\n",
    "\n",
    "    sentenses = read_txt_get_sentenses(file_name)\n",
    "\n",
    "    tokens = []\n",
    "    for sentense in sentenses:\n",
    "        tokens.append(sentense.split())\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "03f3f8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Аннотация', 'Предмет', 'Проблема бедности играет доминирующую роль в экономике России не только как социальная болезнь, но и как образец поведения населения и фактор, влияющий на множество важных показателей страны', 'Бедность это многомерное явление, являющееся результатом влияния большого количества факторов, которые, с одной стороны, воздействуют на все сферы общественного воспроизводства, а с другой могут быть порождены социально-психологической сущностью самого человека', 'В данной статье понятие бедность рассматривается с точки зрения институционального подхода', 'Цели', 'Комплексное авторское исследование проблемы институционализации бедности в России', 'Выработка качественно новой стратегии социально-экономического развития, которая будет ориентирована прежде всего на предупреждение бедности и на борьбу с ее причинами в Российской Федерации', 'Методология', 'В процессе исследования проблемы институционализации бедности использовались методы логического, статистического анализа', 'Результаты', 'На территории Волгоградской области неудовлетворительно ведется борьба с бедностью населения, недостаточно используются возможности региона по улучшению уровня жизни населения', 'Основными направлениями формирования институционального механизма борьбы с бедностью в России и, в частности, в Волгоградской области является работа общественных объединений, фондов, организация банками микрофинансирования предпринимательства, предоставление образовательных кредитов для получения молодежью качественного образования, трудоустройство молодежи и предоставление ей возможности переквалификации в рамках социальной ответственности работодателей']\n",
      "['Ах не говорите мне про Австрию', 'Я ничего не понимаю может быть но Австрия никогда не хотела и не хочет войны', 'Она предает нас', 'Россия одна должна быть спасительницей Европы', 'Наш благодетель знает свое высокое призвание и будет верен ему', 'Вот одно во что я верю', 'Нашему доброму и чудному государю предстоит величайшая роль в мире и он так добродетелен и хорош что Бог не оставит его и он исполнит свое призвание задавить гидру революции которая теперь еще ужаснее в лице этого убийцы и злодея', 'Мы одни должны искупить кровь праведника', 'На кого нам надеяться я вас спрашиваю', 'Англия с своим коммерческим духом не поймет и не может понять всю высоту души императора Александра', 'Она отказалась очистить Мальту', 'Она хочет видеть ищет заднюю мысль наших действий', 'Что они сказали Новосильцеву', 'Ничего', 'Они не поняли они не могли понять самоотвержения нашего императора который ничего не хочет для себя и все хочет для блага мира', 'И что они обещали', 'Ничего', 'И что обещали и того не будет', 'Пруссия уже объявила что Бонапарте непобедим и что вся Европа ничего не может против него', 'И я не верю ни в одном слове ни Гарденбергу ни Гаугвицу', 'Я верю в одного Бога и в высокую судьбу нашего милого императора', 'Он спасет Европу', 'Она вдруг остановилась с улыбкой насмешки над своею горячностью', 'Я думаю сказал князь улыбаясь что ежели бы вас послали вместо нашего милого Винценгероде вы бы взяли приступом согласие прусского короля', 'Вы так красноречивы', 'Вы дадите мне чаю']\n",
      "['В самый разгар пандемии актриса и телеведущая Джоанна Ламли отправляется в эпическое и очень личное путешествие по родной Великобритании', 'Она объедет самые разные уголки Англии Шотландии Уэльса и Северной Ирландии познакомит нас с природными красотами и удивительными достопримечательностями этой многогранной страны', 'Мы побываем в местах где снимали Игру престолов где Брэм Стокер писал своего Дракулу а Беатрис Поттер истории про Кролика Питера', 'От Гебридских островов до графства Корнуолл от английской Ривьеры до Шотландского нагорья отправляйтесь с нами в путешествие по этому крошечному но удивительно разнообразному острову\\n16 февраля 1923 года английский археолог Говард Картер стал первым человеком за 3000 лет вошедшим в погребальную камеру фараона Тутанхамона в Долине Царей', 'За свою недолгую жизнь а скончался он, не дожив до 19-ти Тутанхамон не совершил ничего примечательного однако по иронии судьбы именно ему было суждено стать самым известным правителем Древнего Египта как раз благодаря своей гробнице', 'При этом сам Картер совершивший одно из величайших археологических открытий в истории человечества формального образования практически не имел и фактически был самоучкой']\n"
     ]
    }
   ],
   "source": [
    "# файлы с ручным (эталонным) разбиением на предложения\n",
    "first_txt_true_sentenses = read_txt_get_sentenses(\"токены для научной статьи.txt\")\n",
    "second_txt_true_sentenses = read_txt_get_sentenses(\"токены для художественного текста.txt\")\n",
    "third_txt_true_sentenses = read_txt_get_sentenses(\"токены для новостной статьи.txt\")\n",
    "\n",
    "print(first_txt_true_sentenses)\n",
    "print(second_txt_true_sentenses)\n",
    "print(third_txt_true_sentenses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "572de0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Аннотация'], ['Предмет'], ['Проблема', 'бедности', 'играет', 'доминирующую', 'роль', 'в', 'экономике', 'России', 'не', 'только', 'как', 'социальная', 'болезнь,', 'но', 'и', 'как', 'образец', 'поведения', 'населения', 'и', 'фактор,', 'влияющий', 'на', 'множество', 'важных', 'показателей', 'страны'], ['Бедность', 'это', 'многомерное', 'явление,', 'являющееся', 'результатом', 'влияния', 'большого', 'количества', 'факторов,', 'которые,', 'с', 'одной', 'стороны,', 'воздействуют', 'на', 'все', 'сферы', 'общественного', 'воспроизводства,', 'а', 'с', 'другой', 'могут', 'быть', 'порождены', 'социально-психологической', 'сущностью', 'самого', 'человека'], ['В', 'данной', 'статье', 'понятие', 'бедность', 'рассматривается', 'с', 'точки', 'зрения', 'институционального', 'подхода'], ['Цели'], ['Комплексное', 'авторское', 'исследование', 'проблемы', 'институционализации', 'бедности', 'в', 'России'], ['Выработка', 'качественно', 'новой', 'стратегии', 'социально-экономического', 'развития,', 'которая', 'будет', 'ориентирована', 'прежде', 'всего', 'на', 'предупреждение', 'бедности', 'и', 'на', 'борьбу', 'с', 'ее', 'причинами', 'в', 'Российской', 'Федерации'], ['Методология'], ['В', 'процессе', 'исследования', 'проблемы', 'институционализации', 'бедности', 'использовались', 'методы', 'логического,', 'статистического', 'анализа'], ['Результаты'], ['На', 'территории', 'Волгоградской', 'области', 'неудовлетворительно', 'ведется', 'борьба', 'с', 'бедностью', 'населения,', 'недостаточно', 'используются', 'возможности', 'региона', 'по', 'улучшению', 'уровня', 'жизни', 'населения'], ['Основными', 'направлениями', 'формирования', 'институционального', 'механизма', 'борьбы', 'с', 'бедностью', 'в', 'России', 'и,', 'в', 'частности,', 'в', 'Волгоградской', 'области', 'является', 'работа', 'общественных', 'объединений,', 'фондов,', 'организация', 'банками', 'микрофинансирования', 'предпринимательства,', 'предоставление', 'образовательных', 'кредитов', 'для', 'получения', 'молодежью', 'качественного', 'образования,', 'трудоустройство', 'молодежи', 'и', 'предоставление', 'ей', 'возможности', 'переквалификации', 'в', 'рамках', 'социальной', 'ответственности', 'работодателей']]\n",
      "[['Ах', 'не', 'говорите', 'мне', 'про', 'Австрию'], ['Я', 'ничего', 'не', 'понимаю', 'может', 'быть', 'но', 'Австрия', 'никогда', 'не', 'хотела', 'и', 'не', 'хочет', 'войны'], ['Она', 'предает', 'нас'], ['Россия', 'одна', 'должна', 'быть', 'спасительницей', 'Европы'], ['Наш', 'благодетель', 'знает', 'свое', 'высокое', 'призвание', 'и', 'будет', 'верен', 'ему'], ['Вот', 'одно', 'во', 'что', 'я', 'верю'], ['Нашему', 'доброму', 'и', 'чудному', 'государю', 'предстоит', 'величайшая', 'роль', 'в', 'мире', 'и', 'он', 'так', 'добродетелен', 'и', 'хорош', 'что', 'Бог', 'не', 'оставит', 'его', 'и', 'он', 'исполнит', 'свое', 'призвание', 'задавить', 'гидру', 'революции', 'которая', 'теперь', 'еще', 'ужаснее', 'в', 'лице', 'этого', 'убийцы', 'и', 'злодея'], ['Мы', 'одни', 'должны', 'искупить', 'кровь', 'праведника'], ['На', 'кого', 'нам', 'надеяться', 'я', 'вас', 'спрашиваю'], ['Англия', 'с', 'своим', 'коммерческим', 'духом', 'не', 'поймет', 'и', 'не', 'может', 'понять', 'всю', 'высоту', 'души', 'императора', 'Александра'], ['Она', 'отказалась', 'очистить', 'Мальту'], ['Она', 'хочет', 'видеть', 'ищет', 'заднюю', 'мысль', 'наших', 'действий'], ['Что', 'они', 'сказали', 'Новосильцеву'], ['Ничего'], ['Они', 'не', 'поняли', 'они', 'не', 'могли', 'понять', 'самоотвержения', 'нашего', 'императора', 'который', 'ничего', 'не', 'хочет', 'для', 'себя', 'и', 'все', 'хочет', 'для', 'блага', 'мира'], ['И', 'что', 'они', 'обещали'], ['Ничего'], ['И', 'что', 'обещали', 'и', 'того', 'не', 'будет'], ['Пруссия', 'уже', 'объявила', 'что', 'Бонапарте', 'непобедим', 'и', 'что', 'вся', 'Европа', 'ничего', 'не', 'может', 'против', 'него'], ['И', 'я', 'не', 'верю', 'ни', 'в', 'одном', 'слове', 'ни', 'Гарденбергу', 'ни', 'Гаугвицу'], ['Я', 'верю', 'в', 'одного', 'Бога', 'и', 'в', 'высокую', 'судьбу', 'нашего', 'милого', 'императора'], ['Он', 'спасет', 'Европу'], ['Она', 'вдруг', 'остановилась', 'с', 'улыбкой', 'насмешки', 'над', 'своею', 'горячностью'], ['Я', 'думаю', 'сказал', 'князь', 'улыбаясь', 'что', 'ежели', 'бы', 'вас', 'послали', 'вместо', 'нашего', 'милого', 'Винценгероде', 'вы', 'бы', 'взяли', 'приступом', 'согласие', 'прусского', 'короля'], ['Вы', 'так', 'красноречивы'], ['Вы', 'дадите', 'мне', 'чаю']]\n",
      "[['В', 'самый', 'разгар', 'пандемии', 'актриса', 'и', 'телеведущая', 'Джоанна', 'Ламли', 'отправляется', 'в', 'эпическое', 'и', 'очень', 'личное', 'путешествие', 'по', 'родной', 'Великобритании'], ['Она', 'объедет', 'самые', 'разные', 'уголки', 'Англии', 'Шотландии', 'Уэльса', 'и', 'Северной', 'Ирландии', 'познакомит', 'нас', 'с', 'природными', 'красотами', 'и', 'удивительными', 'достопримечательностями', 'этой', 'многогранной', 'страны'], ['Мы', 'побываем', 'в', 'местах', 'где', 'снимали', 'Игру', 'престолов', 'где', 'Брэм', 'Стокер', 'писал', 'своего', 'Дракулу', 'а', 'Беатрис', 'Поттер', 'истории', 'про', 'Кролика', 'Питера'], ['От', 'Гебридских', 'островов', 'до', 'графства', 'Корнуолл', 'от', 'английской', 'Ривьеры', 'до', 'Шотландского', 'нагорья', 'отправляйтесь', 'с', 'нами', 'в', 'путешествие', 'по', 'этому', 'крошечному', 'но', 'удивительно', 'разнообразному', 'острову', '16', 'февраля', '1923', 'года', 'английский', 'археолог', 'Говард', 'Картер', 'стал', 'первым', 'человеком', 'за', '3000', 'лет', 'вошедшим', 'в', 'погребальную', 'камеру', 'фараона', 'Тутанхамона', 'в', 'Долине', 'Царей'], ['За', 'свою', 'недолгую', 'жизнь', 'а', 'скончался', 'он,', 'не', 'дожив', 'до', '19-ти', 'Тутанхамон', 'не', 'совершил', 'ничего', 'примечательного', 'однако', 'по', 'иронии', 'судьбы', 'именно', 'ему', 'было', 'суждено', 'стать', 'самым', 'известным', 'правителем', 'Древнего', 'Египта', 'как', 'раз', 'благодаря', 'своей', 'гробнице'], ['При', 'этом', 'сам', 'Картер', 'совершивший', 'одно', 'из', 'величайших', 'археологических', 'открытий', 'в', 'истории', 'человечества', 'формального', 'образования', 'практически', 'не', 'имел', 'и', 'фактически', 'был', 'самоучкой']]\n"
     ]
    }
   ],
   "source": [
    "# файлы с ручным (эталонным) разбиением на токены\n",
    "first_txt_true_tokens = read_txt_get_tokens(\"токены для научной статьи.txt\")\n",
    "second_txt_true_tokens = read_txt_get_tokens(\"токены для художественного текста.txt\")\n",
    "third_txt_true_tokens = read_txt_get_tokens(\"токены для новостной статьи.txt\")\n",
    "\n",
    "print(first_txt_true_tokens)\n",
    "print(second_txt_true_tokens)\n",
    "print(third_txt_true_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "80bc9caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбиваем тексты на предложения и токены c помощью созданных нами функций\n",
    "predicted_sentences_1 = split_sentences(text_1)\n",
    "predicted_sentences_2 = split_sentences(text_2)\n",
    "predicted_sentences_3 = split_sentences(text_3)\n",
    "\n",
    "predicted_tokens_1 = [tokenize_text(sentence) for sentence in predicted_sentences_1]\n",
    "predicted_tokens_2 = [tokenize_text(sentence) for sentence in predicted_sentences_2]\n",
    "predicted_tokens_3 = [tokenize_text(sentence) for sentence in predicted_sentences_3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8136cf2f",
   "metadata": {},
   "source": [
    "Для определения точности токенизации можно использовать метрику precision, которая показывает соотношение количества правильно определенных токенов к общему количеству токенов в эталонном разбиении. Напишем функцию, которая сравнивает два списка списков токенов и вычисляет precision:\n",
    "\n",
    "Функция принимает два списка списков токенов - true_tokens и predicted_tokens, соответствующие эталонному разбиению и предсказанию. Сначала функция преобразует каждый список списков токенов в один плоский список токенов. Затем она находит пересечение множеств предсказанных и эталонных токенов, чтобы определить количество правильно предсказанных токенов. Значение precision вычисляется как отношение количества правильно предсказанных токенов к общему количеству предсказанных токенов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "a135b252",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def tokenization_precision(true_tokens, predicted_tokens) -> float:\n",
    "    \"\"\"\n",
    "    Вычисляет precision для списка списков эталонных токенов и списка списков предсказанных токенов.\n",
    "    \n",
    "    Аргументы:\n",
    "    true_tokens: Список списков эталонных токенов.\n",
    "    predicted_tokens: Список списков предсказанных токенов.\n",
    "    \n",
    "    Возвращает:\n",
    "    Значение precision в диапазоне от 0 до 1.\n",
    "    \"\"\"\n",
    "    true_tokens = [token for sentence in true_tokens for token in sentence]\n",
    "    predicted_tokens = [token for sentence in predicted_tokens for token in sentence]\n",
    "\n",
    "    correct_tokens = set(predicted_tokens).intersection(set(true_tokens))\n",
    "    precision = len(correct_tokens) / len(predicted_tokens)\n",
    "\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "8d41316a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision токенизации новостной статьи:\n",
      "0.7262569832402235\n",
      "\n",
      "precision токенизации художественного текста:\n",
      "0.6926229508196722\n",
      "\n",
      "precision токенизации научной статьи:\n",
      "0.8674698795180723\n"
     ]
    }
   ],
   "source": [
    "text_1_scores = tokenization_precision(first_txt_true_tokens, predicted_tokens_1)\n",
    "text_2_scores = tokenization_precision(second_txt_true_tokens, predicted_tokens_2)\n",
    "text_3_scores = tokenization_precision(third_txt_true_tokens, predicted_tokens_3)\n",
    "\n",
    "print(f'precision токенизации новостной статьи:\\n{text_1_scores}\\n')\n",
    "print(f'precision токенизации художественного текста:\\n{text_2_scores}\\n')\n",
    "print(f'precision токенизации научной статьи:\\n{text_3_scores}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "e2440772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_precision(true_sentences, predicted_sentences):\n",
    "    \"\"\"\n",
    "    Определяет точность разбиения на предложения.\n",
    "    \n",
    "    Аргументы:\n",
    "    true_sentences - список эталонных предложений\n",
    "    predicted_sentences - список предложений, полученных в результате тестирования\n",
    "    \n",
    "    Возвращает:\n",
    "    Значение точности в диапазоне от 0 до 1.\n",
    "    \"\"\"\n",
    "    if len(predicted_sentences) == 0:\n",
    "        return 0\n",
    "    \n",
    "    true_positives = 0\n",
    "    \n",
    "    for sentence in predicted_sentences:\n",
    "        if sentence in true_sentences:\n",
    "            true_positives += 1\n",
    "    \n",
    "    precision = true_positives / len(predicted_sentences)\n",
    "    \n",
    "    return precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b8915b",
   "metadata": {},
   "source": [
    "Эта функция сравнивает список эталонных предложений true_sentences с полученным в результате тестирования списком предложений test_sentences и вычисляет точность разбиения на предложения.\n",
    "\n",
    "Для вычисления точности используется метрика precision, которая показывает соотношение количества правильно определенных предложений к общему количеству предложений в полученном списке predicted_sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "ba568304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision разбиения на предложения новостной статьи:\n",
      "1.0\n",
      "\n",
      "precision разбиения на предложения научной статьи:\n",
      "1.0\n",
      "\n",
      "precision разбиения на предложения художественного текста:\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "text_1_scores = sentence_precision(real_sentences1, sentences1)\n",
    "text_2_scores = sentence_precision(real_sentences1, sentences1)\n",
    "text_3_scores = sentence_precision(real_sentences1, sentences1)\n",
    "\n",
    "print(f'precision разбиения на предложения новостной статьи:\\n{text_1_scores}\\n')\n",
    "print(f'precision разбиения на предложения научной статьи:\\n{text_2_scores}\\n')\n",
    "print(f'precision разбиения на предложения художественного текста:\\n{text_3_scores}')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b57e38b",
   "metadata": {},
   "source": [
    "Теперь сравним результаты работы самостоятельно написанной функции с готовой функией из nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "f3e16b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_by_nltk_text_1 = del_punct(nltk_tokenization(text_1))\n",
    "tokens_by_nltk_text_2 = del_punct(nltk_tokenization(text_2))\n",
    "tokens_by_nltk_text_3 = del_punct(nltk_tokenization(text_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "f73f69da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision токенизации новостной статьи:\n",
      "0.7262569832402235\n",
      "\n",
      "precision токенизации художественного текста:\n",
      "0.680161943319838\n",
      "\n",
      "precision токенизации научной статьи:\n",
      "0.8181818181818182\n"
     ]
    }
   ],
   "source": [
    "text_1_scores = tokenization_precision(first_txt_true_tokens, tokens_by_nltk_text_1)\n",
    "text_2_scores = tokenization_precision(second_txt_true_tokens, tokens_by_nltk_text_2)\n",
    "text_3_scores = tokenization_precision(third_txt_true_tokens, tokens_by_nltk_text_3)\n",
    "\n",
    "print(f'precision токенизации новостной статьи:\\n{text_1_scores}\\n')\n",
    "print(f'precision токенизации художественного текста:\\n{text_2_scores}\\n')\n",
    "print(f'precision токенизации научной статьи:\\n{text_3_scores}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c125bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
